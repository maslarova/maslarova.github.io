---
layout: post
title:  "6. cvičenie 25.3.2021"
date:   2021-03-22 11:26:13 +0100
---


V rámci 6. cvičenia dokončíme aproximáciu funkcií. Konkrétne sa budeme venovať metóde najmenších štvorcov a aproximácii derivácií. 
 <br />

<font size="4">  <span style="color:green"><b> Minimalizácia - metóda najmenších štvorcov</b></span></font>  <br />
Majme body $(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$, kde $n \in \mathbb{N}$. Chceme určiť nejaký funkčný predpis, ktorý by dobre aproximoval vývoj týchto bodov. Z minimalizačných metód si bližšie priblížime metódu najmenších štvorcov. Táto aproximačná metóda je veľmi bežná, a pravdepodobne ste sa s ňou už i stretli, keď ste nejaké, napr. experimentálne dáta fitovali vhodnou funkciou. 

Ukážme si najprv túto metódu na lineárnej funkcii. 
Máme dáta 

  <table align="center">
        <tr >
            <td>$i$</td>
            <td>1</td>
            <td>2</td>
            <td>3</td>
            <td>4</td>
            <td>5</td>
        </tr>

        <tr >
            <td>$x_i$</td>
            <td>0</td>
            <td>1</td>
            <td>3</td>
            <td>5</td>
            <td>6</td>
        </tr>

        <tr >
            <td>$y_i$</td>
            <td>5</td>
            <td>3</td>
            <td>3</td>
            <td>2</td>
            <td>1</td>
        </tr>
    </table>
<br />
Budeme ich chcieť aproximovať lineárnou funkciou. 
Pripomeňme si, že aproximačná funkcia nemusí pri minimalizácii prechádzať zadanými bodmi. Na obrázku vidíte aproximačnú funkciu $f(x)  = ax+b$, kde $a=-0,54$ a $b=4,42$ (zakrúhlene na 2 desatinné miesta), ktorá bola získaná metódou najmenších štvorcov. 

<br />
![](http://maslarova.github.io/cvicenie6/lin_fun_suma.png?raw=true)
<br />

Hodnoty $s_1, s_2, s_3, s_4, s_5$ sú vzdialenosti bodov $(x_1,y_1), (x_2,y_2), (x_3,y_3), (x_4, y_4), (x_5, y_5)$ od $f(x_1),f(x_2),f(x_3),f(x_4),f(x_5)$. 
Koeficienty je možné získať tak, že najprv vypočítame súčet druhých mocnín týchto vzdialeností od $f(x)$. Následne hľadáme koeficienty $a ,b$, pre ktoré má tento súčet minimum. Všimnime si, že druhé mocniny $s_1, s_2, s_3, s_4, s_5$ zodpovedajú 
obsahu zelených štvorcov na obrázku, minimalizujeme teda súčet obsahov týchto štvorcov - odtiaľ ten názov metódy. Minimalizujeme teda  

{: .centering}
$S (a,b)=  s_1^2+s_2^2+ s_3^2+ s_4^2 + s_5^2$,

{: .centering}
$S (a,b)=  (y_1-ax_1-b)^2+(y_2-ax_2-b)^2+ (y_3-ax_3-b)^2+ (y_4-ax_4-b)^2 + (y_5-ax_5-b)^2$,

{: .centering}
$S (a,b)=  \sum_{i=1}^{5} (y_i-ax_i-b)^2$.

Pre všeobecné $n \in \mathbb{N}$ by sme mohli písať

{: .centering}

$S (a,b)=  \sum_{i=1}^{n} (y_i-ax_i-b)^2$.


Poďme si túto funkciu zderivovať:

{: .centering}
$\frac{\partial S}{\partial a}  = \frac{\partial}{\partial a}\sum_{i=1}^{n} (y_i-ax_i-b)^2 = -2\sum_{i=1}^{n}x_i(y_i-ax_i-b)$, 


{: .centering}
$\frac{\partial S}{\partial b}  = \frac{\partial}{\partial b}\sum_{i=1}^{n} (y_i-ax_i-b)^2 = -2\sum_{i=1}^{n}(y_i-ax_i-b)$.


Derivácie položíme rovné 0, pretože hľadáme minimum funkcie $S$ v $a$ a $b$. 
Získavame sústavu lineárnych rovníc s neznámymi $a$ a $b$ :

{: .centering}
$a \sum_{i=1}^{n}x_i^2 + b \sum_{i=1}^{n}x_i = \sum_{i=1}^{n}y_i x_i$,

{: .centering}
$a \sum_{i=1}^{n}x_i + b n = \sum_{i=1}^{n}y_i$.

Prepíšeme do maticového tvaru:

{: .centering}
$\begin{pmatrix} \sum_{i=1}^{n}x_i^2 & \sum_{i=1}^{n}x_i\\\ \sum_{i=1}^{n}x_i & n\end{pmatrix} \cdot \begin{pmatrix}a \\\ b\end{pmatrix} = \begin{pmatrix} \sum_{i=1}^{n}y_i x_i \\\ \sum_{i=1}^{n}y_i \end{pmatrix} $.


Len poznamenajme, že výraz "$n$" sme matici dostali v rovnici preto, lebo $\sum_{i=1}^{n}b = b \sum_{i=1}^{n} 1 =b n$.

Ak chceme aproximovať dáta kvadratickou funkciou (kvadratickou v premennej $x$), budeme postupovať rovnakým spôsobom. Odvodenie môžete nájsť tu -> [pdf s odvodením metódy najmenších štvorcov pre kvadratickú aproximáciu](http://maslarova.github.io/cvicenie6/kvadraticka_funkce.pdf). 

Tutorial, ako si metódu najmenších štvorcov naprogramovať pre lineárnu aproximáciu v Matlabe, si môžete pozrieť v nasledujúcom videu: 
{% include youtube.html id="RpCxRZrMTQ0" %}
 <br />
Programy pre lineárnu i kvadratickú aproximáciu si môžete stiahnuť tu:
- [Program s aproximáciou bodov lineárnou funkciou](http://maslarova.github.io/cvicenie6/najm_ctverce_lin.m)
- [Program s aproximáciou bodov kvadratickou funkciou](http://maslarova.github.io/cvicenie6/najm_ctverce_kvadr.m)

Niekedy máme body, ktoré majú rôznu dôležitosť. Predstavte si napr. situáciu, že jeden bod máte nameraný s nižšou presnosťou než bod iný, a chcete ho do aproximácie zahrnúť "menej", než bod, ktorý je nameraný presnejšie. V takom prípade môžu dobre poslúžiť vážené najmenšie štvorce. 
Funkcia na minimalizovanie by potom vyzerala nasledovne:

{: .centering}
$S=  \sum_{i=1}^{n} w_i (y_i-f(x_i))^2$.

Reálne čísla $w_i$ predstavujú váhy, a môžu byť pre každé $(x_i,y_i)$ rôzne. Môžeme si všimnúť, že ak sú všetky $w_i=w\in \mathbb{R}$  rovnaké, vážené najmenšie štvorce prejdu v klasické najmenšie štvorce. Ak totiž položíme derivácie rovné 0, tak sa $w$ vykráti.

V rámci cvičenia sme si vyskúšali len **diskrétnu aproximáciu** najmenšími štvorcami. Takisto však existuje **spojitá aproximácia**, ako si môžete naštudovať i v tomto [pdf-ku](http://kfe.fjfi.cvut.cz/~limpouch/numet/aprox.pdf).
V takom prípade môže byť pre aproximáciu zadaný celý interval, nielen v diskrétne body. 

A prečo druhé mocniny vzdialeností $f(x)$ od $y_i$ a nie priamo absolútne hodnoty?
Nedá sa to jednoducho povedať, v skutočnosti sa používajú oba prístupy. Absolutné hodnoty môžu byť výhodné napr. v prípade, že máme v dátach "outliery". To sú body, ktoré sa výrazne líšia od ostatných bodov. Napr. pri experimentálnych dátach to môže byť nameraná hodnota spôsobená hrubou chybou, ktorá je výrazne mimo očakávanej závislosti. Ak túto hodnotu vopred nevylúčime, najmenšie štvorce budú brať do úvahy celý obsah štvorca tohto bodu, ktorý bude omnoho väčší než štvorce ostatných bodov. 
Najmenšie štvorce budú teda oveľa výraznejšie "ťahať" aproximačnú krivku k tomu outlieru než absolútna hodnota, čo je vo väčšine prípadov principiálne zle.

Na druhej strane, metóda najmenších štvorcov je stabilná. Malá zmena dát nespôsobí veľkú zmenu v koeficientoch aproximovanej funkcie. Naopak pri minimalizácii, ktorá používa súčet absolutných hodnôt vzdialeností $f(x)$ od $y_i$ môže malá zmena dátach zapríčíniť veľkú zmenu v aproximovanej funkcii. Preto sa metóda najmenších štvorcov hodí pre veľmi veľké spektrum úloh.

V skutočnosti vždy záleží na konkrétnej úlohe, ktorú z metód aproximácie volíme, či už sa jedná o interpoláciu alebo minimalizáciu. Je dobré si vždy limity konkrétnej metódy preštudovať a uvážiť, či je metóda vhodná pre pre naše dáta. 
Pri metóde najmenších štvorcov i aproximačných metódach sa zároveň ponúka otázka, akou funkciou dané dáta aproximovať. Pokiaľ máme napr. namerané dáta s očakávanou závislosťou, tak vieme, že to bude napr. lineárna či exponenciálna funkcia. 

V realite sme ale častokrát postavení pred hodnoty, pri ktorých závislosť nevieme, ba naopak, chceme ju z daných dát odvodiť. Jednou možnosťou je vykresliť si graficky body a odhadnúť závislosť "by oko". Dobrým príkladom, čo by sa mohlo stať, kebyže nemáme prehľad o tom, aké dáta fitujeme, je [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet). Na obrázkoch vidíte, že 4 rôzne množiny dát dávajú pri fitovaní úplne rovnakú lineárnu funkciu. 
Hneď od pohľadu je však jasné, že pre niektoré z týchto bodov nedáva lineárna aproximácia žiaden zmysel, alebo že outlier zapríčinil nesprávny sklon funkcie. Pozoruhodné je, že tieto 4 sety majú rovnaké aj iné štatistické veličiny, ako napr.  varianciu (čo je druhá mocnina štandardnej odchýlky).
Kontext je preto v rámci dát veľmi dôležitý. Problém je hlavne s predikciou dát do budúcna, nedostatočným počtom dát, či nepresnými údajmi. Napr. i začiatok exponenciály sa dá veľmi pekne fitnúť parabolickou funkciou.

Túto tému dobre vystihuje i výrok slávneho John von Neumanna "With four parameters I can fit an elephant, and with five I can make him wiggle his trunk." 
Ak budete si budete chcieť prečitať, ako Enrico Fermi zachránil dobrou intuíciou roky kariéry iného vedca, článok nájdete tu ->
[https://www.nature.com/articles/427297a](https://www.nature.com/articles/427297a).




<font size="4">  <span style="color:green"><b>Aproximácia derivácií</b></span></font>  <br />
S aproximáciami derivácii ste sa už stretli na 2. cvičení, kde sme si odvodzovali rád metódy pre aproximácie derivácií.
V tomto [súbore](http://maslarova.github.io/cvicenie5/aproxder.pdf) si to môžete pripomenúť, a pozrieť sa, ako nájsť aproximáciu pomocou konečnej diferencie, ak máme zadaný počet okolitých bodov, ktoré chceme pri aproximácii využiť (viz. tiež prednáška). <br />

V tomto [súbore](http://maslarova.github.io/cvicenie5/derivace2.m) nájdete implementácie aproximácií derivácie funkcie sin($x$) v Matlabe. Tento program demonštruje, ako sa mení chyba aproximácie  derivácie s dĺžkou kroku $h$. 


Aproximácie derivácii si môžeme v tomto prípade dobre porovnať s analytickým riešením, ktoré poznáme. Pozrite sa najprv na posledné riadky programu, kde definujeme nasledujúce funkcie: výpočet funkcie $sin(x)$ v bode $x$, výpočet jej analytickej derivácie cos($x$), a odhady derivácie metódami 1. a 2. rádu.
Funkcia df_n1, ktorá vracia hodnotu

{: .centering}
`df = ( f(x+h)-f(x) ) / h`

implementuje aproxímáciu 1. rádu, tzv. doprednú diferenciu:

{: .centering}
$f'(x)\sim\frac{f(x+h)-f(x)}{h}$.


Funkcia f_n2 , ktorá  ktorá vracia hodnotu

{: .centering}
`df = ( f(x+h/2)-f(x-h/2) ) / h`

implementuje aproxímáciu 2. rádu, tzv. centrálnu diferenciu, v tvare

{: .centering}
$f'(x)\sim\frac{f(x+h/2)-f(x-h/2)}{h}$.

Na začiatku programu sme si potom preddefinovali vektory, do ktorých budeme ukladať priebežne napočítané výsledky, pre rôzne hodnoty $h$, ktoré budeme ukladať do vektoru h_arr.

Definujeme si potom konkrétne $x$, v ktorom budeme aproximácie počítať, napr. v tomto prípade $\pi/6$. Následne vypočítame analytickú deriváciu cos($\pi/6$). Následne si zvolíme konečne krátky krok $h$, ktorý bude reprezentovať náhradu nekonečne krátkeho kroku d$x$ v klasickej definície derivácie. Začneme s krokom veľkosti $\pi$ (intuitívne asi tušíte, že tento krok je ako náhrada nekonečne krátkeho kroku príliš veľký pre $x=\pi/6$).

Následne budeme v cykle postupne krok $h$ zmenšovať a ukladať si výsledky aproximácie do vektorov.
V závere si chyby aproximácií vykreslíme.
Všimnite si, že existuje niečo ako "ideálna" voľbu kroku. Pre príliš veľký krok totiž narážame na chybu metódy, zatiaľ čo s voľbou príliš malého kroku nám problémy spôsobuje zaokrúhľovacia chyba.



Vyskúšajte si program spustiť, príp. vyskúšajte, ako funguje aproximácia pre iné funkcie či hodnoty $x$ a podobne.
<br />
 
Pri učení na skúšku si nezabudnite pozrieť aj vyhodnocovanie funkcií a všetky ostatné veci z prednášky.


